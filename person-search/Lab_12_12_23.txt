         [ 1.3303e-01,  3.7854e-02,  8.6636e-02,  ..., -3.9688e-02,
           2.6224e-04,  1.8997e-01],
         [ 1.5161e-01,  5.8682e-02,  4.7494e-02,  ..., -4.7263e-02,
          -1.0292e-02,  2.3875e-01],
         [ 2.5739e-01, -4.5215e-01,  3.0363e-01,  ..., -2.1110e-01,
           6.4169e-01,  5.3024e-01]],

        [[ 1.4257e-01,  1.0367e-01,  4.9626e-02,  ..., -1.4055e-03,
          -2.4368e-02,  1.4010e-01],
         [ 1.6550e-01,  5.2351e-02,  5.3657e-02,  ...,  4.8036e-03,
          -2.3912e-02,  1.8138e-01],
         [ 1.7729e-01, -6.5739e-02,  1.0575e-01,  ...,  8.3282e-02,
           2.1140e-01,  2.2936e-01],
         ...,
         [ 1.5048e-01,  6.5824e-02,  9.6436e-02,  ..., -9.6409e-03,
           2.2443e-02,  1.9736e-01],
         [ 2.8441e-01,  1.2827e-01,  1.6805e-01,  ..., -8.1877e-02,
           6.0534e-02,  8.5068e-02],
         [ 1.5346e-01,  6.1417e-02,  4.5446e-02,  ...,  4.2976e-02,
          -3.5593e-02,  2.0202e-01]],

        ...,

        [[ 1.4383e-01,  5.7049e-02,  3.9843e-02,  ..., -3.6265e-03,
          -4.0134e-02,  1.3164e-01],
         [-1.0873e-01, -4.5042e-01,  4.3080e-01,  ..., -7.9948e-01,
           6.6752e-01,  3.2727e-01],
         [ 1.3082e-01,  3.3356e-02,  9.4448e-02,  ..., -6.3894e-02,
           9.9523e-02,  1.0481e-01],
         ...,
         [ 2.0403e-01, -1.1052e-03,  1.1084e-01,  ..., -3.2049e-02,
          -1.0439e-02,  1.8488e-01],
         [ 1.7946e-01,  1.4091e-03,  1.0914e-01,  ..., -1.3732e-01,
          -1.9396e-02,  1.8728e-01],
         [ 1.6193e-01,  4.9411e-02,  3.4366e-02,  ...,  2.6171e-03,
          -4.5542e-03,  2.1330e-01]],

        [[ 1.7051e-01,  1.1486e-01,  6.3614e-02,  ...,  5.4797e-03,
          -2.0564e-02,  1.4196e-01],
         [ 2.3385e-01,  6.3729e-02,  1.3963e-01,  ...,  4.1603e-02,
          -2.7710e-02,  1.7561e-01],
         [ 2.3417e-01,  1.6674e-01,  2.2673e-01,  ..., -5.1315e-02,
           7.4699e-02,  2.2532e-01],
         ...,
         [ 4.4562e-01,  1.7486e-01,  2.0132e-01,  ..., -1.5164e-01,
           1.6836e-01,  2.2481e-01],
         [ 1.8967e-01,  6.9985e-02,  1.3985e-01,  ..., -9.6957e-02,
           4.4805e-02,  2.2303e-01],
         [ 4.2267e-01, -1.6500e-01, -7.7410e-02,  ..., -7.7896e-01,
          -2.0243e-01, -6.4543e-01]],

        [[ 1.4769e-01,  9.6552e-02,  3.1767e-02,  ...,  4.2564e-03,
          -2.1373e-02,  1.2421e-01],
         [ 3.1786e-01,  2.7704e-02,  2.2839e-01,  ..., -2.0022e-02,
           3.3020e-01,  4.0324e-01],
         [ 1.5523e-01,  2.2117e-02,  1.0030e-01,  ...,  1.4113e-02,
          -2.2007e-02,  1.4724e-01],
         ...,
         [ 2.1219e-01,  6.2299e-02,  7.4447e-02,  ...,  1.0972e-02,
           2.0092e-02,  1.9456e-01],
         [ 2.1944e-01,  3.3767e-03,  4.9296e-02,  ..., -2.5672e-02,
          -8.3384e-03,  2.4003e-01],
         [ 1.5800e-01,  5.5057e-02,  9.0356e-02,  ..., -4.1321e-02,
           3.6564e-02,  2.0163e-01]]], device='cuda:0',
       grad_fn=<NativeLayerNormBackward0>)
This is my labels: tensor([[-100, -100, -100, -100, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, -100, -100, -100],
        [-100, -100, 2158, -100, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, -100, -100, -100],
        [-100, -100, -100, 2038, -100, 2304, -100, -100],
        [-100, 2023, -100, -100, -100, -100, -100, -100],
        [-100, -100, -100, 2003, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, 6379, -100, -100],
        [-100, -100, -100, -100, -100, 3239, -100, 2229]], device='cuda:0')
This is my prediction: tensor([[[5.6226e-12, 1.6026e-07, 3.2478e-08,  ..., 4.1198e-09,
          1.0895e-07, 2.3464e-08],
         [2.2919e-13, 1.1743e-10, 9.8578e-11,  ..., 1.7544e-10,
          2.1540e-09, 2.5436e-10],
         [5.6810e-13, 9.1185e-11, 6.6084e-11,  ..., 2.4179e-11,
          1.6985e-11, 1.3440e-12],
         ...,
         [1.2136e-11, 1.4673e-10, 3.4816e-11,  ..., 4.4236e-11,
          2.4536e-10, 1.9785e-10],
         [2.7483e-10, 6.0874e-10, 1.0665e-09,  ..., 7.5130e-10,
          2.0157e-11, 6.7137e-10],
         [7.6234e-10, 2.1511e-09, 6.2635e-09,  ..., 2.4381e-09,
          8.7509e-11, 2.4766e-09]],

        [[1.0409e-11, 2.5415e-07, 5.1092e-08,  ..., 6.9910e-09,
          9.6246e-08, 1.4929e-08],
         [1.5589e-12, 2.0618e-10, 2.2532e-10,  ..., 2.2607e-10,
          2.3073e-09, 4.4346e-10],
         [3.0628e-13, 3.0327e-10, 6.3566e-11,  ..., 3.6483e-11,
          4.2116e-11, 6.1250e-12],
         ...,
         [1.0304e-10, 4.5353e-10, 8.1926e-11,  ..., 6.2414e-11,
          2.8603e-10, 4.6862e-10],
         [2.7949e-09, 6.7667e-06, 6.9192e-07,  ..., 6.4851e-08,
          2.1475e-06, 1.5007e-07],
         [1.7532e-11, 5.5643e-07, 1.8534e-07,  ..., 1.9586e-08,
          4.6062e-07, 6.7830e-08]],

        [[7.8155e-12, 6.8313e-07, 8.4591e-08,  ..., 2.9844e-08,
          2.3344e-07, 9.8004e-08],
         [1.0012e-12, 2.1349e-10, 2.9531e-10,  ..., 1.6905e-10,
          2.2939e-09, 6.8643e-10],
         [4.4474e-13, 5.3270e-11, 3.3866e-10,  ..., 4.9880e-12,
          1.6317e-10, 2.5511e-11],
         ...,
         [1.3343e-10, 1.7408e-09, 2.1060e-10,  ..., 4.5254e-10,
          3.8097e-11, 4.4283e-10],
         [2.3997e-09, 3.4884e-06, 7.5701e-07,  ..., 1.8892e-08,
          1.3785e-06, 1.9689e-07],
         [7.9561e-12, 2.8802e-07, 2.1609e-08,  ..., 2.4107e-08,
          1.1414e-07, 7.5920e-09]],

        ...,

        [[1.2539e-10, 7.9415e-08, 2.3368e-07,  ..., 1.9018e-08,
          4.9418e-08, 4.9263e-08],
         [1.2973e-11, 1.4678e-10, 5.8721e-10,  ..., 2.8976e-10,
          3.9886e-10, 2.2284e-10],
         [1.2100e-13, 1.7051e-10, 1.6052e-10,  ..., 6.4645e-11,
          7.1720e-10, 1.1579e-10],
         ...,
         [1.5720e-11, 4.9638e-11, 3.9968e-11,  ..., 2.6579e-11,
          3.1193e-10, 1.2088e-10],
         [5.1980e-10, 3.4914e-10, 6.4918e-10,  ..., 4.2741e-10,
          2.5299e-11, 1.4160e-10],
         [7.7056e-10, 6.3238e-10, 1.1272e-09,  ..., 1.3086e-09,
          1.0768e-10, 2.8203e-10]],

        [[9.6099e-11, 7.8858e-07, 6.7840e-07,  ..., 3.7887e-08,
          1.8840e-07, 3.5700e-08],
         [1.0499e-12, 6.0259e-11, 3.7725e-11,  ..., 1.5317e-12,
          1.4859e-10, 2.5944e-11],
         [2.1845e-13, 4.3781e-10, 4.2447e-10,  ..., 6.9494e-11,
          8.1525e-12, 1.5843e-11],
         ...,
         [1.3345e-11, 8.5653e-10, 1.0659e-09,  ..., 7.0433e-10,
          5.1602e-12, 1.6731e-11],
         [7.1722e-12, 1.4276e-09, 5.1198e-10,  ..., 6.9288e-10,
          4.8301e-12, 1.7311e-11],
         [1.9331e-11, 1.3519e-09, 8.3255e-10,  ..., 4.0257e-10,
          1.1344e-11, 2.3785e-11]],

        [[1.7044e-10, 4.1503e-08, 1.3377e-07,  ..., 5.7176e-09,
          1.8079e-06, 3.1929e-08],
         [6.3413e-13, 4.7251e-11, 5.6246e-11,  ..., 1.8424e-11,
          1.4437e-10, 3.7601e-11],
         [2.4843e-13, 4.5553e-11, 5.0216e-11,  ..., 5.7609e-12,
          5.0261e-11, 1.9902e-11],
         ...,
         [9.8574e-11, 1.4404e-09, 5.6708e-09,  ..., 2.5682e-09,
          5.8429e-09, 1.2454e-08],
         [1.9265e-09, 1.7663e-09, 2.3922e-09,  ..., 2.2041e-09,
          8.3143e-08, 5.2974e-09],
         [2.1136e-10, 1.4114e-10, 8.0572e-11,  ..., 9.8609e-11,
          1.3454e-10, 5.0061e-11]]], device='cuda:0')
This is my alpha: 0.0002935995302407516
This is my mlm_output: MaskedLMOutput(loss=tensor(1.9004, device='cuda:0', grad_fn=<AddBackward0>), logits=tensor([[[-26.1673, -16.3332, -17.4221,  ..., -19.3560, -16.8200, -18.2709],
         [-20.9237, -14.3162, -13.9621,  ..., -14.4302, -12.2276, -13.4404],
         [-20.1239, -14.7750, -14.3859,  ..., -16.7994, -15.1163, -17.6509],
         ...,
         [-16.7680, -14.8951, -15.4985,  ..., -17.4272, -13.8230, -13.9900],
         [-10.6318, -10.4140,  -9.3026,  ...,  -8.9186, -11.9693,  -9.8684],
         [-25.3275, -15.9572, -16.4141,  ..., -18.3555, -14.7294, -16.9521]],

        [[-21.6656, -16.8204, -18.1557,  ..., -21.2703, -16.7858, -19.4321],
         [-20.3143, -15.6962, -15.7424,  ..., -15.3246, -12.3142, -13.7507],
         [-21.5261, -14.4518, -14.7610,  ..., -17.1346, -16.0138, -17.7662],
         ...,
         [-18.8083, -14.5101, -16.3719,  ..., -16.1109, -13.1954, -14.0117],
         [-12.2403, -10.6600,  -9.3704,  ...,  -9.2633, -11.6299, -11.5084],
         [-13.1598, -10.1198,  -9.5922,  ...,  -9.5071, -11.5628, -11.6133]],

        [[-26.0633, -14.5706, -16.6168,  ..., -19.2920, -14.5024, -15.6515],
         [-19.3284, -13.5762, -13.8121,  ..., -14.4926, -10.9700, -11.7273],
         [-20.1521, -14.9063, -13.2215,  ..., -17.8103, -13.2084, -13.6204],
         ...,
         [-14.2684, -13.6765, -13.0919,  ..., -13.0705, -14.1121, -11.7202],
         [-25.1853, -14.3007, -15.3469,  ..., -18.1034, -14.4486, -16.1055],
         [-10.8624,  -9.4720, -10.0111,  ..., -10.1869, -12.3075, -10.3400]],

        ...,

        [[-25.1141, -18.9883, -18.1642,  ..., -21.2565, -17.4835, -21.0115],
         [-18.4311, -17.1106, -14.7104,  ..., -16.5812, -15.3390, -14.8835],
         [-23.6262, -14.9346, -15.3868,  ..., -16.9535, -13.6797, -15.8394],
         ...,
         [-16.6692, -16.5970, -16.1377,  ..., -15.7024, -13.9890, -14.5407],
         [-10.5619, -11.1887, -10.1297,  ..., -10.8610, -12.8977, -11.9899],
         [ -9.6211, -11.2431, -10.2629,  ..., -10.5360, -12.7048, -12.3279]],

        [[-25.9070, -15.5251, -16.2128,  ..., -19.4814, -15.4794, -16.0620],
         [-23.0490, -16.8681, -18.1329,  ..., -19.3838, -14.1550, -16.1042],
         [-21.9720, -14.0651, -13.5556,  ..., -14.9907, -15.7606, -15.5245],
         ...,
         [-12.8301,  -9.7949,  -9.3522,  ...,  -8.8506, -12.1869, -11.5863],
         [-13.1451, -10.0017, -10.2098,  ...,  -9.5770, -12.3338, -11.6338],
         [-12.8776,  -9.5350,  -8.9441,  ...,  -9.1539, -11.8358, -11.0125]],

        [[-24.9737, -19.1755, -18.4713,  ..., -20.6228, -15.1489, -19.3756],
         [-23.2183, -17.1531, -15.3044,  ..., -18.0688, -14.5765, -15.6702],
         [-21.3140, -15.4276, -15.6206,  ..., -17.7378, -14.3985, -17.0800],
         ...,
         [-13.3938, -10.7807, -10.2818,  ..., -10.9723, -10.3980, -10.0745],
         [-13.2841, -13.9886, -13.1125,  ..., -13.2658,  -9.2197, -12.1348],
         [-11.0311, -11.3117, -11.7773,  ..., -11.3091, -11.3865, -11.8826]]],
       device='cuda:0', grad_fn=<ViewBackward0>), hidden_states=None, attentions=None) and loss_mlm is mlm_output.loss
This is my mrtd_labels: tensor([[-100,    0,    0,    0,    0,    0, -100, -100],
        [-100,    0,    0,    0,    0,    0, -100, -100],
        [-100,    1,    1,    0,    1,    1, -100, -100],
        [-100,    0,    0,    1,    0,    0, -100, -100],
        [-100,    0,    0,    1,    1,    0, -100, -100],
        [-100,    0,    1,    1,    0,    0, -100, -100],
        [-100,    0,    0,    0,    0,    0, -100, -100],
        [-100,    1,    0,    0,    0,    0, -100, -100],
        [-100,    0,    0,    0,    0,    1, -100, -100],
        [-100,    1,    0,    0,    0,    0,    0,    0]], device='cuda:0')
When it is output_MRTD: 


This is output_mrtd: BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2052,  0.0382, -0.2854,  ...,  0.1981,  0.2650,  0.0378],
         [-0.2117, -0.0087, -0.1953,  ...,  0.3337,  0.1751, -0.2418],
         [-0.3168,  0.2141,  0.3398,  ..., -0.1551,  0.8004, -0.1313],
         ...,
         [-0.0463, -0.1302, -1.0089,  ...,  0.2634,  0.5788,  0.0521],
         [ 0.7830, -0.0659, -0.8787,  ...,  0.3767,  0.6060,  0.0774],
         [ 0.1822, -0.0613, -0.2233,  ...,  0.1174,  0.1734,  0.0060]],

        [[ 0.1442, -0.0909, -0.2280,  ...,  0.0932,  0.2952,  0.0787],
         [-0.4042,  0.2346, -0.2413,  ...,  0.3749,  0.2407, -0.5957],
         [ 0.1693,  0.3393,  0.0145,  ...,  0.2545,  0.6195, -0.1379],
         ...,
         [ 0.1317, -0.0923, -0.6396,  ...,  0.1507,  0.1305,  0.2523],
         [ 0.1799, -0.1005, -0.2908,  ...,  0.0277,  0.2760, -0.0899],
         [ 0.7485, -0.0407, -0.7261,  ...,  0.1751,  0.2428, -0.0961]],

        [[ 0.1133, -0.1939, -0.1104,  ...,  0.3017,  0.1257,  0.2164],
         [-0.0538, -0.3051, -0.2876,  ...,  0.7135, -0.1796,  0.0271],
         [-0.0432, -0.0241, -0.3231,  ...,  0.4818,  0.3782, -0.3294],
         ...,
         [ 0.4191, -0.0803, -0.3211,  ...,  0.2956, -0.3011,  0.2312],
         [ 0.8231,  0.0021, -0.1365,  ...,  0.5011,  0.1020, -0.2464],
         [ 0.8372, -0.1339, -0.0028,  ...,  0.6583,  0.0250, -0.1269]],

        ...,

        [[ 0.2252, -0.1267,  0.1293,  ...,  0.1412,  0.1540, -0.2129],
         [-1.4008,  0.2627, -0.0389,  ..., -0.0066,  0.0825,  0.6188],
         [-1.2047, -0.2499,  0.0050,  ..., -0.0136,  0.6833, -0.1192],
         ...,
         [-0.5083, -0.6256,  0.0567,  ...,  0.0432,  0.4976,  0.7266],
         [ 0.1489, -0.0536,  0.1527,  ...,  0.1248,  0.1916,  0.2892],
         [ 0.0837, -0.2999,  0.0288,  ...,  0.1477,  0.0872, -0.2291]],

        [[ 0.2883, -0.4588, -0.0795,  ...,  0.0457,  0.2683,  0.0531],
         [-0.2153, -0.0632, -0.3802,  ..., -0.0359, -0.0032,  0.1848],
         [-0.4028,  0.4178, -0.1603,  ...,  0.1943,  0.2523, -0.3607],
         ...,
         [-0.0458,  0.5095, -0.1020,  ..., -0.4025,  0.1367, -0.9398],
         [ 0.7705,  0.2524, -0.2617,  ...,  0.3242,  0.3752, -0.3235],
         [ 0.7409,  0.1183, -0.3775,  ...,  0.4552,  0.5271, -0.2649]],

        [[ 0.3957, -0.0095, -0.2433,  ...,  0.0121,  0.2863,  0.0974],
         [-0.1336, -0.2336, -0.1261,  ...,  0.3428,  0.3626, -0.5268],
         [-0.2402, -0.2326,  0.2615,  ..., -0.0212,  0.4342, -1.7851],
         ...,
         [-0.1785,  0.5284,  0.4095,  ...,  0.2486, -0.0859, -0.2162],
         [-0.6941,  1.0830, -0.3912,  ..., -0.3325,  0.6532, -0.7442],
         [ 0.2938,  0.7119,  0.4957,  ...,  0.5167,  0.2469,  0.2356]]],
       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=None, hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None) 

This is my text1: {'input_ids': tensor([[  101,  1996,  2158,  2003,  5102,  1999,     0,     0],
        [  101,  1996,  2158,  2003,  4147,  1037,     0,     0],
        [  101,  1996,  2611, 11651,  2422,  6910,     0,     0],
        [  101,  1037,  2158,  4147,  1037,  2417,     0,     0],
        [  101,  1037,  2146,  2601, 10681,  2450,     0,     0],
        [  101,  1996,  2879,  2038,  2460,  2304,     0,     0],
        [  101,  2023,  2450,  2003,  4147,  1037,     0,     0],
        [  101,  2023,  2711,  2003,  5710,  2013,     0,     0],
        [  101,  1037,  2450,  4147,  1037,  6379,     0,     0],
        [  101,  2023,  2402,  2711,  2038,  3239, 15621,  2229]],
       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')} 

This is my text1.attention_mask: tensor([[1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0') 

This is my image_atts: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0') 

This is my image1 for image_embeds = self.visual_encoder(image1): tensor([[[[-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00],
          [-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00],
          [-6.0979e-01, -5.2220e-01, -4.9300e-01,  ..., -2.4483e-01,
           -3.1782e-01, -2.0103e-01],
          ...,
          [-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00],
          [-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00],
          [-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00]],

         [[-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00],
          [-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00],
          [-5.6648e-01, -4.7644e-01, -4.4642e-01,  ..., -2.3631e-01,
           -2.9634e-01, -1.7628e-01],
          ...,
          [-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00],
          [-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00],
          [-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00]],

         [[-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00],
          [-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00],
          [-3.9949e-01, -2.9995e-01, -2.7151e-01,  ..., -5.8213e-02,
           -1.0087e-01,  2.7107e-02],
          ...,
          [-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00],
          [-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00],
          [-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00]]],


        [[[ 8.7925e-01,  4.9969e-01,  4.7049e-01,  ...,  1.9303e+00,
            1.9303e+00,  1.9303e+00],
          [ 9.5224e-01,  5.7268e-01,  6.6027e-01,  ...,  1.2442e+00,
            1.1858e+00,  1.1420e+00],
          [ 5.5808e-01,  5.2889e-01,  6.6027e-01,  ..., -4.0541e-01,
           -5.2220e-01, -5.8059e-01],
          ...,
          [ 1.1128e+00,  2.0772e-01, -2.5943e-01,  ..., -9.4555e-01,
           -5.2220e-01, -6.2439e-01],
          [ 1.2296e+00,  2.2232e-01, -1.8644e-01,  ..., -5.6599e-01,
           -5.5140e-01, -7.5577e-01],
          [-1.4264e-01, -5.3680e-01, -7.1198e-01,  ..., -4.2001e-01,
           -4.6381e-01, -7.8497e-01]],

         [[ 1.0093e+00,  6.1913e-01,  5.8911e-01,  ...,  2.0749e+00,
            2.0749e+00,  2.0749e+00],
          [ 1.0994e+00,  7.0918e-01,  7.9922e-01,  ...,  1.3695e+00,
            1.3245e+00,  1.2795e+00],
          [ 6.9417e-01,  6.6415e-01,  7.9922e-01,  ..., -3.2636e-01,
           -4.3141e-01, -4.7644e-01],
          ...,
          [ 1.1444e+00,  2.1392e-01, -2.8134e-01,  ..., -8.8165e-01,
           -4.6143e-01, -6.2651e-01],
          [ 1.0544e+00,  3.3827e-02, -3.5637e-01,  ..., -4.7644e-01,
           -4.6143e-01, -7.1656e-01],
          [-3.4137e-01, -7.4658e-01, -8.9665e-01,  ..., -3.2636e-01,
           -3.7138e-01, -7.1656e-01]],

         [[ 1.1647e+00,  8.0921e-01,  7.8077e-01,  ...,  2.1459e+00,
            2.1459e+00,  2.1459e+00],
          [ 1.2074e+00,  8.5187e-01,  9.3719e-01,  ...,  1.4776e+00,
            1.4207e+00,  1.3638e+00],
          [ 7.9499e-01,  7.6655e-01,  8.9453e-01,  ..., -1.2931e-01,
           -2.4307e-01, -3.4261e-01],
          ...,
          [ 1.0936e+00,  2.1197e-01, -2.5729e-01,  ..., -7.1234e-01,
           -2.9995e-01, -4.4215e-01],
          [ 9.7985e-01,  1.2887e-02, -3.7105e-01,  ..., -3.4261e-01,
           -3.2839e-01, -5.5592e-01],
          [-3.4261e-01, -7.2656e-01, -8.8298e-01,  ..., -2.0041e-01,
           -2.4307e-01, -5.7014e-01]]],


        [[[ 1.6393e-01,  1.0553e-01,  1.9312e-01,  ..., -9.3096e-01,
           -6.2439e-01,  3.2541e-02],
          [ 1.7853e-01,  1.3473e-01,  1.7853e-01,  ..., -7.1198e-01,
           -2.4483e-01, -4.2001e-01],
          [ 2.3692e-01,  9.0935e-02,  6.1738e-02,  ..., -3.0322e-01,
           -4.2001e-01, -5.2220e-01],
          ...,
          [-2.5853e-02, -2.5853e-02, -2.5853e-02,  ..., -7.5577e-01,
           -8.5796e-01, -1.4264e-01],
          [ 2.2232e-01,  1.7853e-01,  1.3473e-01,  ..., -7.9957e-01,
           -5.6599e-01, -6.9648e-02],
          [ 2.3692e-01,  2.0772e-01,  1.7853e-01,  ...,  7.6336e-02,
            1.4933e-01,  1.7853e-01]],

         [[ 1.2387e-01,  6.3843e-02,  1.5389e-01,  ..., -1.0017e+00,
           -6.8655e-01, -2.6204e-02],
          [ 2.1392e-01,  1.5389e-01,  2.1392e-01,  ..., -6.8655e-01,
           -2.0630e-01, -3.8639e-01],
          [ 3.3398e-01,  1.8391e-01,  1.5389e-01,  ..., -1.7628e-01,
           -3.1135e-01, -4.1641e-01],
          ...,
          [-8.6235e-02, -7.1227e-02, -7.1227e-02,  ..., -7.3157e-01,
           -8.2162e-01, -1.0124e-01],
          [ 1.0887e-01,  7.8851e-02,  3.3827e-02,  ..., -8.0661e-01,
           -5.8149e-01, -8.6235e-02],
          [ 1.0887e-01,  6.3843e-02,  3.3827e-02,  ...,  7.8851e-02,
            1.2387e-01,  1.2387e-01]],

         [[ 1.4087e-01,  8.3987e-02,  1.6931e-01,  ..., -7.9766e-01,
           -4.5637e-01,  2.1197e-01],
          [ 1.9775e-01,  1.4087e-01,  1.8353e-01,  ..., -5.5592e-01,
           -7.2433e-02, -2.4307e-01],
          [ 2.6885e-01,  1.2665e-01,  9.8208e-02,  ..., -1.5775e-01,
           -2.5729e-01, -3.7105e-01],
          ...,
          [ 9.8208e-02,  9.8208e-02,  9.8208e-02,  ..., -4.7060e-01,
           -5.5592e-01,  1.2665e-01],
          [ 3.2573e-01,  2.8307e-01,  2.4041e-01,  ..., -5.1326e-01,
           -2.9995e-01,  1.8353e-01],
          [ 3.2573e-01,  2.9729e-01,  2.6885e-01,  ...,  3.5417e-01,
            3.9683e-01,  4.1105e-01]]],


        ...,


        [[[ 1.7942e-02, -4.7840e-01, -2.4483e-01,  ..., -5.0760e-01,
           -6.9738e-01, -7.1198e-01],
          [ 1.0553e-01,  3.6830e-01,  7.4786e-01,  ..., -8.5796e-01,
           -7.9957e-01, -5.5140e-01],
          [-1.1255e-02,  1.9312e-01, -5.5140e-01,  ..., -6.9738e-01,
           -5.6599e-01, -3.4702e-01],
          ...,
          [-2.1563e-01, -3.1782e-01,  5.1429e-01,  ...,  9.0845e-01,
            9.9604e-01,  8.9385e-01],
          [-2.5853e-02, -2.5943e-01,  5.2889e-01,  ...,  1.0982e+00,
            8.7925e-01,  1.0106e+00],
          [ 4.8509e-01, -2.7403e-01,  1.0553e-01,  ...,  8.6465e-01,
            7.3327e-01,  6.8947e-01]],

         [[-8.6235e-02, -6.1151e-01, -3.5637e-01,  ..., -5.6648e-01,
           -7.7659e-01, -7.9160e-01],
          [ 7.8851e-02,  3.4899e-01,  7.3919e-01,  ..., -8.5163e-01,
           -7.7659e-01, -5.2146e-01],
          [ 4.8835e-02,  2.5894e-01, -5.2146e-01,  ..., -5.8149e-01,
           -4.1641e-01, -2.0630e-01],
          ...,
          [-8.6235e-02, -1.9129e-01,  6.7916e-01,  ...,  1.1894e+00,
            1.2945e+00,  1.1744e+00],
          [ 1.0887e-01, -1.1625e-01,  6.9417e-01,  ...,  1.3845e+00,
            1.1594e+00,  1.2945e+00],
          [ 6.6415e-01, -1.3126e-01,  2.5894e-01,  ...,  1.1444e+00,
            1.0093e+00,  9.6431e-01]],

         [[-7.4078e-01, -1.2100e+00, -9.6830e-01,  ..., -1.0252e+00,
           -1.2100e+00, -1.2243e+00],
          [-5.1326e-01, -2.4307e-01,  1.6931e-01,  ..., -1.3096e+00,
           -1.2669e+00, -1.0252e+00],
          [-4.5637e-01, -2.4307e-01, -8.4032e-01,  ..., -1.0821e+00,
           -9.8252e-01, -7.8344e-01],
          ...,
          [ 3.2573e-01,  1.9775e-01,  9.7985e-01,  ...,  1.3922e+00,
            1.4918e+00,  1.3780e+00],
          [ 4.8215e-01,  2.4041e-01,  9.9407e-01,  ...,  1.5771e+00,
            1.3638e+00,  1.4918e+00],
          [ 9.6563e-01,  2.1197e-01,  5.5325e-01,  ...,  1.3496e+00,
            1.2216e+00,  1.1789e+00]]],


        [[[-1.1061e+00, -1.1061e+00, -1.0769e+00,  ..., -8.7256e-01,
           -8.4336e-01, -8.1417e-01],
          [-1.1207e+00, -1.1061e+00, -1.0915e+00,  ..., -9.3096e-01,
           -9.0176e-01, -8.8716e-01],
          [-1.1061e+00, -1.0915e+00, -1.0623e+00,  ..., -9.6015e-01,
           -9.3096e-01, -9.1636e-01],
          ...,
          [-1.2804e-01, -2.0103e-01, -2.7403e-01,  ..., -8.4247e-02,
            1.6393e-01,  4.1210e-01],
          [ 1.9312e-01,  2.2232e-01,  2.5152e-01,  ..., -2.5853e-02,
           -5.5050e-02, -8.4247e-02],
          [ 8.0626e-01,  8.5005e-01,  8.5005e-01,  ...,  1.7853e-01,
            1.7853e-01,  1.6393e-01]],

         [[-1.0617e+00, -1.0617e+00, -1.0317e+00,  ..., -7.7659e-01,
           -7.4658e-01, -7.1656e-01],
          [-1.0767e+00, -1.0617e+00, -1.0467e+00,  ..., -8.5163e-01,
           -8.2162e-01, -7.9160e-01],
          [-1.0617e+00, -1.0467e+00, -1.0167e+00,  ..., -8.8165e-01,
           -8.5163e-01, -8.3662e-01],
          ...,
          [-1.0124e-01, -1.7628e-01, -2.5132e-01,  ..., -1.1625e-01,
            1.3888e-01,  3.9401e-01],
          [ 2.2893e-01,  2.5894e-01,  2.8896e-01,  ..., -7.1227e-02,
           -1.0124e-01, -1.4627e-01],
          [ 8.5925e-01,  9.0428e-01,  9.0428e-01,  ...,  1.2387e-01,
            1.2387e-01,  1.0887e-01]],

         [[-8.5454e-01, -8.5454e-01, -8.2610e-01,  ..., -7.1234e-01,
           -6.8390e-01, -6.5546e-01],
          [-8.6876e-01, -8.5454e-01, -8.4032e-01,  ..., -7.5500e-01,
           -7.2656e-01, -7.1234e-01],
          [-8.5454e-01, -8.4032e-01, -8.1188e-01,  ..., -7.6922e-01,
           -7.4078e-01, -7.2656e-01],
          ...,
          [ 6.9767e-02, -1.3329e-03, -7.2433e-02,  ...,  4.1327e-02,
            2.6885e-01,  5.1059e-01],
          [ 3.8261e-01,  4.1105e-01,  4.3949e-01,  ...,  8.3987e-02,
            5.5547e-02,  1.2887e-02],
          [ 9.7985e-01,  1.0225e+00,  1.0225e+00,  ...,  2.8307e-01,
            2.6885e-01,  2.5463e-01]]],


        [[[-1.5879e+00, -1.5879e+00, -1.5879e+00,  ..., -1.3251e+00,
           -1.3251e+00, -1.3251e+00],
          [-1.6025e+00, -1.6025e+00, -1.6025e+00,  ..., -1.1061e+00,
           -1.1061e+00, -1.1061e+00],
          [-1.4419e+00, -1.4127e+00, -1.3835e+00,  ..., -1.0915e+00,
           -1.0915e+00, -1.0915e+00],
          ...,
          [-1.8644e-01, -1.8644e-01, -1.8644e-01,  ..., -6.9648e-02,
           -6.9648e-02, -5.5050e-02],
          [-1.7184e-01, -1.7184e-01, -1.7184e-01,  ..., -8.4247e-02,
           -8.4247e-02, -8.4247e-02],
          [-9.8845e-02, -9.8845e-02, -9.8845e-02,  ..., -5.5050e-02,
           -5.5050e-02, -4.0451e-02]],

         [[-1.4820e+00, -1.4820e+00, -1.4820e+00,  ..., -1.2418e+00,
           -1.2418e+00, -1.2418e+00],
          [-1.4970e+00, -1.4970e+00, -1.4970e+00,  ..., -1.0167e+00,
           -1.0167e+00, -1.0167e+00],
          [-1.3319e+00, -1.3019e+00, -1.2718e+00,  ..., -1.0017e+00,
           -1.0017e+00, -1.0017e+00],
          ...,
          [-4.1212e-02, -4.1212e-02, -4.1212e-02,  ...,  7.8851e-02,
            7.8851e-02,  9.3858e-02],
          [-2.6204e-02, -2.6204e-02, -2.6204e-02,  ...,  6.3843e-02,
            6.3843e-02,  6.3843e-02],
          [ 4.8835e-02,  4.8835e-02,  4.8835e-02,  ...,  9.3858e-02,
            9.3858e-02,  1.0887e-01]],

         [[-1.1674e+00, -1.1674e+00, -1.1674e+00,  ..., -1.0394e+00,
           -1.0394e+00, -1.0394e+00],
          [-1.2100e+00, -1.2243e+00, -1.2243e+00,  ..., -8.2610e-01,
           -8.2610e-01, -8.2610e-01],
          [-1.0821e+00, -1.0678e+00, -1.0252e+00,  ..., -8.1188e-01,
           -8.1188e-01, -8.1188e-01],
          ...,
          [ 1.2665e-01,  1.2665e-01,  1.2665e-01,  ...,  2.4041e-01,
            2.4041e-01,  2.5463e-01],
          [ 1.4087e-01,  1.4087e-01,  1.4087e-01,  ...,  2.2619e-01,
            2.2619e-01,  2.2619e-01],
          [ 2.1197e-01,  2.1197e-01,  2.1197e-01,  ...,  2.5463e-01,
            2.5463e-01,  2.6885e-01]]]], device='cuda:0') and it got shape like: torch.Size([10, 3, 50, 50])
This is my image_embeds: tensor([[[ 0.1541,  0.0862,  0.0641,  ...,  0.0246, -0.0250,  0.1589],
         [ 0.5674, -0.6399,  0.7045,  ..., -0.0473,  0.9982,  0.3949],
         [ 0.2204,  0.0418,  0.1704,  ..., -0.0261,  0.1022,  0.1124],
         ...,
         [ 0.2368,  0.1566,  0.2304,  ..., -0.0717,  0.0414,  0.2112],
         [ 0.3139,  0.1343,  0.2724,  ..., -0.0294,  0.0879,  0.1551],
         [ 0.1995,  0.0105,  0.0520,  ..., -0.0304, -0.0193,  0.1457]],

        [[ 0.1340,  0.1013,  0.0475,  ...,  0.0058, -0.0771,  0.1505],
         [ 0.1741,  0.0751,  0.1568,  ..., -0.0353, -0.0028,  0.1558],
         [ 0.1602,  0.0280,  0.0683,  ..., -0.0671, -0.0277,  0.1750],
         ...,
         [ 0.1499,  0.0409,  0.1273,  ..., -0.0286,  0.0450,  0.2034],
         [ 0.1597,  0.0736,  0.1423,  ..., -0.0968,  0.0247,  0.1887],
         [ 0.5074, -0.5890,  1.2512,  ...,  1.0293, -0.0617, -0.5687]],

        [[ 0.1266,  0.0939,  0.0153,  ..., -0.0259, -0.0250,  0.1189],
         [ 0.6926, -0.6044,  0.7723,  ..., -0.0815,  0.0043, -0.9114],
         [ 0.1743,  0.0447,  0.0947,  ..., -0.0316,  0.0184,  0.1583],
         ...,
         [ 0.2609,  0.0264,  0.1870,  ..., -0.1727,  0.0912,  0.1907],
         [ 0.1736,  0.0570,  0.0135,  ..., -0.0106,  0.0089,  0.1499],
         [ 0.1828,  0.0806,  0.0395,  ..., -0.0461,  0.0105,  0.1668]],

        ...,

        [[ 0.1359,  0.0829,  0.0424,  ...,  0.0109, -0.0211,  0.1273],
         [ 0.1518,  0.0569,  0.0390,  ..., -0.0023,  0.0225,  0.1899],
         [ 0.1486,  0.1779,  0.1798,  ..., -0.0667,  0.1047,  0.1766],
         ...,
         [ 0.1542,  0.0614,  0.0989,  ..., -0.0848,  0.1294,  0.1588],
         [ 0.1917,  0.1007,  0.1021,  ..., -0.0486,  0.0383,  0.1200],
         [-0.0193,  0.0302,  0.5687,  ...,  0.0816,  0.7720,  0.0343]],

        [[ 0.1337,  0.0959,  0.0412,  ..., -0.0053, -0.0455,  0.1515],
         [ 0.2724, -0.4261,  0.8493,  ...,  0.5147,  0.8799, -0.7197],
         [ 0.1448,  0.0558,  0.1592,  ..., -0.0884,  0.0414,  0.2842],
         ...,
         [ 0.1625,  0.0731,  0.0883,  ..., -0.0094, -0.0018,  0.2019],
         [ 0.1666,  0.0534,  0.1282,  ..., -0.0272,  0.0152,  0.2635],
         [ 0.1984, -0.0013,  0.0504,  ...,  0.0533, -0.0123,  0.1857]],

        [[ 0.1454,  0.0991,  0.0520,  ..., -0.0132, -0.0323,  0.1332],
         [ 0.3527, -0.5358,  0.0392,  ..., -0.1661,  0.5457,  0.2593],
         [ 0.1768,  0.0632,  0.1305,  ..., -0.0352,  0.0244,  0.1050],
         ...,
         [ 0.2757,  0.0409,  0.1362,  ..., -0.0767,  0.1350,  0.2082],
         [ 0.2565,  0.0557,  0.1120,  ..., -0.0394, -0.0105,  0.1527],
         [ 0.1916,  0.0697,  0.0562,  ..., -0.0244, -0.0132,  0.2122]]],
       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)
This is my image2 in image_embeds_m = self.visual_encoder_m(image2): tensor([[[[-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00],
          [-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00],
          [-6.0979e-01, -5.2220e-01, -4.9300e-01,  ..., -2.4483e-01,
           -3.1782e-01, -2.0103e-01],
          ...,
          [-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00],
          [-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00],
          [-1.7923e+00, -1.7923e+00, -1.7923e+00,  ..., -1.7923e+00,
           -1.7923e+00, -1.7923e+00]],

         [[-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00],
          [-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00],
          [-5.6648e-01, -4.7644e-01, -4.4642e-01,  ..., -2.3631e-01,
           -2.9634e-01, -1.7628e-01],
          ...,
          [-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00],
          [-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00],
          [-1.7521e+00, -1.7521e+00, -1.7521e+00,  ..., -1.7521e+00,
           -1.7521e+00, -1.7521e+00]],

         [[-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00],
          [-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00],
          [-3.9949e-01, -2.9995e-01, -2.7151e-01,  ..., -5.8213e-02,
           -1.0087e-01,  2.7107e-02],
          ...,
          [-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00],
          [-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00],
          [-1.4802e+00, -1.4802e+00, -1.4802e+00,  ..., -1.4802e+00,
           -1.4802e+00, -1.4802e+00]]],


        [[[ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  4.7049e-01,
            4.9969e-01,  8.7925e-01],
          [ 1.1420e+00,  1.1858e+00,  1.2442e+00,  ...,  6.6027e-01,
            5.7268e-01,  9.5224e-01],
          [-5.8059e-01, -5.2220e-01, -4.0541e-01,  ...,  6.6027e-01,
            5.2889e-01,  5.5808e-01],
          ...,
          [-6.2439e-01, -5.2220e-01, -9.4555e-01,  ..., -2.5943e-01,
            2.0772e-01,  1.1128e+00],
          [-7.5577e-01, -5.5140e-01, -5.6599e-01,  ..., -1.8644e-01,
            2.2232e-01,  1.2296e+00],
          [-7.8497e-01, -4.6381e-01, -4.2001e-01,  ..., -7.1198e-01,
           -5.3680e-01, -1.4264e-01]],

         [[ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  5.8911e-01,
            6.1913e-01,  1.0093e+00],
          [ 1.2795e+00,  1.3245e+00,  1.3695e+00,  ...,  7.9922e-01,
            7.0918e-01,  1.0994e+00],
          [-4.7644e-01, -4.3141e-01, -3.2636e-01,  ...,  7.9922e-01,
            6.6415e-01,  6.9417e-01],
          ...,
          [-6.2651e-01, -4.6143e-01, -8.8165e-01,  ..., -2.8134e-01,
            2.1392e-01,  1.1444e+00],
          [-7.1656e-01, -4.6143e-01, -4.7644e-01,  ..., -3.5637e-01,
            3.3827e-02,  1.0544e+00],
          [-7.1656e-01, -3.7138e-01, -3.2636e-01,  ..., -8.9665e-01,
           -7.4658e-01, -3.4137e-01]],

         [[ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  7.8077e-01,
            8.0921e-01,  1.1647e+00],
          [ 1.3638e+00,  1.4207e+00,  1.4776e+00,  ...,  9.3719e-01,
            8.5187e-01,  1.2074e+00],
          [-3.4261e-01, -2.4307e-01, -1.2931e-01,  ...,  8.9453e-01,
            7.6655e-01,  7.9499e-01],
          ...,
          [-4.4215e-01, -2.9995e-01, -7.1234e-01,  ..., -2.5729e-01,
            2.1197e-01,  1.0936e+00],
          [-5.5592e-01, -3.2839e-01, -3.4261e-01,  ..., -3.7105e-01,
            1.2887e-02,  9.7985e-01],
          [-5.7014e-01, -2.4307e-01, -2.0041e-01,  ..., -8.8298e-01,
           -7.2656e-01, -3.4261e-01]]],


        [[[ 1.6393e-01,  1.0553e-01,  1.9312e-01,  ..., -9.3096e-01,
           -6.2439e-01,  3.2541e-02],
          [ 1.7853e-01,  1.3473e-01,  1.7853e-01,  ..., -7.1198e-01,
           -2.4483e-01, -4.2001e-01],
          [ 2.3692e-01,  9.0935e-02,  6.1738e-02,  ..., -3.0322e-01,
           -4.2001e-01, -5.2220e-01],
          ...,
          [-2.5853e-02, -2.5853e-02, -2.5853e-02,  ..., -7.5577e-01,
           -8.5796e-01, -1.4264e-01],
          [ 2.2232e-01,  1.7853e-01,  1.3473e-01,  ..., -7.9957e-01,
           -5.6599e-01, -6.9648e-02],
          [ 2.3692e-01,  2.0772e-01,  1.7853e-01,  ...,  7.6336e-02,
            1.4933e-01,  1.7853e-01]],

         [[ 1.2387e-01,  6.3843e-02,  1.5389e-01,  ..., -1.0017e+00,
           -6.8655e-01, -2.6204e-02],
          [ 2.1392e-01,  1.5389e-01,  2.1392e-01,  ..., -6.8655e-01,
           -2.0630e-01, -3.8639e-01],
          [ 3.3398e-01,  1.8391e-01,  1.5389e-01,  ..., -1.7628e-01,
           -3.1135e-01, -4.1641e-01],
          ...,
          [-8.6235e-02, -7.1227e-02, -7.1227e-02,  ..., -7.3157e-01,
           -8.2162e-01, -1.0124e-01],
          [ 1.0887e-01,  7.8851e-02,  3.3827e-02,  ..., -8.0661e-01,
           -5.8149e-01, -8.6235e-02],
          [ 1.0887e-01,  6.3843e-02,  3.3827e-02,  ...,  7.8851e-02,
            1.2387e-01,  1.2387e-01]],

         [[ 1.4087e-01,  8.3987e-02,  1.6931e-01,  ..., -7.9766e-01,
           -4.5637e-01,  2.1197e-01],
          [ 1.9775e-01,  1.4087e-01,  1.8353e-01,  ..., -5.5592e-01,
           -7.2433e-02, -2.4307e-01],
          [ 2.6885e-01,  1.2665e-01,  9.8208e-02,  ..., -1.5775e-01,
           -2.5729e-01, -3.7105e-01],
          ...,
          [ 9.8208e-02,  9.8208e-02,  9.8208e-02,  ..., -4.7060e-01,
           -5.5592e-01,  1.2665e-01],
          [ 3.2573e-01,  2.8307e-01,  2.4041e-01,  ..., -5.1326e-01,
           -2.9995e-01,  1.8353e-01],
          [ 3.2573e-01,  2.9729e-01,  2.6885e-01,  ...,  3.5417e-01,
            3.9683e-01,  4.1105e-01]]],


        ...,


        [[[ 1.7942e-02, -4.7840e-01, -2.4483e-01,  ..., -5.0760e-01,
           -6.9738e-01, -7.1198e-01],
          [ 1.0553e-01,  3.6830e-01,  7.4786e-01,  ..., -8.5796e-01,
           -7.9957e-01, -5.5140e-01],
          [-1.1255e-02,  1.9312e-01, -5.5140e-01,  ..., -6.9738e-01,
           -5.6599e-01, -3.4702e-01],
          ...,
          [-2.1563e-01, -3.1782e-01,  5.1429e-01,  ...,  9.0845e-01,
            9.9604e-01,  8.9385e-01],
          [-2.5853e-02, -2.5943e-01,  5.2889e-01,  ...,  1.0982e+00,
            8.7925e-01,  1.0106e+00],
          [ 4.8509e-01, -2.7403e-01,  1.0553e-01,  ...,  8.6465e-01,
            7.3327e-01,  6.8947e-01]],

         [[-8.6235e-02, -6.1151e-01, -3.5637e-01,  ..., -5.6648e-01,
           -7.7659e-01, -7.9160e-01],
          [ 7.8851e-02,  3.4899e-01,  7.3919e-01,  ..., -8.5163e-01,
           -7.7659e-01, -5.2146e-01],
          [ 4.8835e-02,  2.5894e-01, -5.2146e-01,  ..., -5.8149e-01,
           -4.1641e-01, -2.0630e-01],
          ...,
          [-8.6235e-02, -1.9129e-01,  6.7916e-01,  ...,  1.1894e+00,
            1.2945e+00,  1.1744e+00],
          [ 1.0887e-01, -1.1625e-01,  6.9417e-01,  ...,  1.3845e+00,
            1.1594e+00,  1.2945e+00],
          [ 6.6415e-01, -1.3126e-01,  2.5894e-01,  ...,  1.1444e+00,
            1.0093e+00,  9.6431e-01]],

         [[-7.4078e-01, -1.2100e+00, -9.6830e-01,  ..., -1.0252e+00,
           -1.2100e+00, -1.2243e+00],
          [-5.1326e-01, -2.4307e-01,  1.6931e-01,  ..., -1.3096e+00,
           -1.2669e+00, -1.0252e+00],
          [-4.5637e-01, -2.4307e-01, -8.4032e-01,  ..., -1.0821e+00,
           -9.8252e-01, -7.8344e-01],
          ...,
          [ 3.2573e-01,  1.9775e-01,  9.7985e-01,  ...,  1.3922e+00,
            1.4918e+00,  1.3780e+00],
          [ 4.8215e-01,  2.4041e-01,  9.9407e-01,  ...,  1.5771e+00,
            1.3638e+00,  1.4918e+00],
          [ 9.6563e-01,  2.1197e-01,  5.5325e-01,  ...,  1.3496e+00,
            1.2216e+00,  1.1789e+00]]],


        [[[-8.1417e-01, -8.4336e-01, -8.7256e-01,  ..., -1.0769e+00,
           -1.1061e+00, -1.1061e+00],
          [-8.8716e-01, -9.0176e-01, -9.3096e-01,  ..., -1.0915e+00,
           -1.1061e+00, -1.1207e+00],
          [-9.1636e-01, -9.3096e-01, -9.6015e-01,  ..., -1.0623e+00,
           -1.0915e+00, -1.1061e+00],
          ...,
          [ 4.1210e-01,  1.6393e-01, -8.4247e-02,  ..., -2.7403e-01,
           -2.0103e-01, -1.2804e-01],
          [-8.4247e-02, -5.5050e-02, -2.5853e-02,  ...,  2.5152e-01,
            2.2232e-01,  1.9312e-01],
          [ 1.6393e-01,  1.7853e-01,  1.7853e-01,  ...,  8.5005e-01,
            8.5005e-01,  8.0626e-01]],

         [[-7.1656e-01, -7.4658e-01, -7.7659e-01,  ..., -1.0317e+00,
           -1.0617e+00, -1.0617e+00],
          [-7.9160e-01, -8.2162e-01, -8.5163e-01,  ..., -1.0467e+00,
           -1.0617e+00, -1.0767e+00],
          [-8.3662e-01, -8.5163e-01, -8.8165e-01,  ..., -1.0167e+00,
           -1.0467e+00, -1.0617e+00],
          ...,
          [ 3.9401e-01,  1.3888e-01, -1.1625e-01,  ..., -2.5132e-01,
           -1.7628e-01, -1.0124e-01],
          [-1.4627e-01, -1.0124e-01, -7.1227e-02,  ...,  2.8896e-01,
            2.5894e-01,  2.2893e-01],
          [ 1.0887e-01,  1.2387e-01,  1.2387e-01,  ...,  9.0428e-01,
            9.0428e-01,  8.5925e-01]],

         [[-6.5546e-01, -6.8390e-01, -7.1234e-01,  ..., -8.2610e-01,
           -8.5454e-01, -8.5454e-01],
          [-7.1234e-01, -7.2656e-01, -7.5500e-01,  ..., -8.4032e-01,
           -8.5454e-01, -8.6876e-01],
          [-7.2656e-01, -7.4078e-01, -7.6922e-01,  ..., -8.1188e-01,
           -8.4032e-01, -8.5454e-01],
          ...,
          [ 5.1059e-01,  2.6885e-01,  4.1327e-02,  ..., -7.2433e-02,
           -1.3329e-03,  6.9767e-02],
          [ 1.2887e-02,  5.5547e-02,  8.3987e-02,  ...,  4.3949e-01,
            4.1105e-01,  3.8261e-01],
          [ 2.5463e-01,  2.6885e-01,  2.8307e-01,  ...,  1.0225e+00,
            1.0225e+00,  9.7985e-01]]],


        [[[-1.3251e+00, -1.3251e+00, -1.3251e+00,  ..., -1.5879e+00,
           -1.5879e+00, -1.5879e+00],
          [-1.1061e+00, -1.1061e+00, -1.1061e+00,  ..., -1.6025e+00,
           -1.6025e+00, -1.6025e+00],
          [-1.0915e+00, -1.0915e+00, -1.0915e+00,  ..., -1.3835e+00,
           -1.4127e+00, -1.4419e+00],
          ...,
          [-5.5050e-02, -6.9648e-02, -6.9648e-02,  ..., -1.8644e-01,
           -1.8644e-01, -1.8644e-01],
          [-8.4247e-02, -8.4247e-02, -8.4247e-02,  ..., -1.7184e-01,
           -1.7184e-01, -1.7184e-01],
          [-4.0451e-02, -5.5050e-02, -5.5050e-02,  ..., -9.8845e-02,
           -9.8845e-02, -9.8845e-02]],

         [[-1.2418e+00, -1.2418e+00, -1.2418e+00,  ..., -1.4820e+00,
           -1.4820e+00, -1.4820e+00],
          [-1.0167e+00, -1.0167e+00, -1.0167e+00,  ..., -1.4970e+00,
           -1.4970e+00, -1.4970e+00],
          [-1.0017e+00, -1.0017e+00, -1.0017e+00,  ..., -1.2718e+00,
           -1.3019e+00, -1.3319e+00],
          ...,
          [ 9.3858e-02,  7.8851e-02,  7.8851e-02,  ..., -4.1212e-02,
           -4.1212e-02, -4.1212e-02],
          [ 6.3843e-02,  6.3843e-02,  6.3843e-02,  ..., -2.6204e-02,
           -2.6204e-02, -2.6204e-02],
          [ 1.0887e-01,  9.3858e-02,  9.3858e-02,  ...,  4.8835e-02,
            4.8835e-02,  4.8835e-02]],

         [[-1.0394e+00, -1.0394e+00, -1.0394e+00,  ..., -1.1674e+00,
           -1.1674e+00, -1.1674e+00],
          [-8.2610e-01, -8.2610e-01, -8.2610e-01,  ..., -1.2243e+00,
           -1.2243e+00, -1.2100e+00],
          [-8.1188e-01, -8.1188e-01, -8.1188e-01,  ..., -1.0252e+00,
           -1.0678e+00, -1.0821e+00],
          ...,
          [ 2.5463e-01,  2.4041e-01,  2.4041e-01,  ...,  1.2665e-01,
            1.2665e-01,  1.2665e-01],
          [ 2.2619e-01,  2.2619e-01,  2.2619e-01,  ...,  1.4087e-01,
            1.4087e-01,  1.4087e-01],
          [ 2.6885e-01,  2.5463e-01,  2.5463e-01,  ...,  2.1197e-01,
            2.1197e-01,  2.1197e-01]]]], device='cuda:0') and it shape is: torch.Size([10, 3, 50, 50])
This is my labels = input_ids.clone(): tensor([[ 101, 2023, 2402, 2158, 2038, 3244],
        [ 101, 1037, 2450, 7883, 1037, 2304],
        [ 101, 1037, 2158, 2003, 4147, 1037],
        [ 101, 2002, 2003, 1999, 1037, 3756],
        [ 101, 1996, 3124, 2003, 4147, 2304],
        [ 101, 1996, 2158, 2038, 2460, 2304],
        [ 101, 1037, 2450, 4147, 1037, 2417],
        [ 101, 1037, 2158, 2007, 2460, 2304],
        [ 101, 2027, 2024, 4147, 1037, 4462],
        [ 101, 2023, 2158, 2003, 4147, 1037]], device='cuda:0')
This is my  self.text_encoder.config.vocab_size: 30522
This is input_ids: tensor([[ 101, 2023,  103, 2158, 2038, 3244],
        [ 101, 1037, 2450, 7883, 1037, 2304],
        [ 101, 1037, 2158, 2003, 4147, 1037],
        [ 101, 2002,  103, 1999, 1037, 3756],
        [ 101, 1996, 3124,  103, 4147,  103],
        [ 101, 1996, 2158, 2038,  103, 2304],
        [ 101, 1037, 2450, 4147,  103, 2417],
        [ 101, 1037, 2158, 2007, 2460, 2304],
        [ 101, 2027, 2024, 4147, 1037, 4462],
        [ 101, 2023, 2158, 2003, 4147,  103]], device='cuda:0')


This is targets=labels (format=(labels)): tensor([[-100, -100, 2402, -100, -100, -100],
        [-100, -100, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, -100],
        [-100, -100, 2003, -100, -100, -100],
        [-100, 1996, -100, 2003, -100, 2304],
        [-100, -100, -100, -100, 2460, -100],
        [-100, 1037, -100, -100, 1037, -100],
        [-100, -100, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, 1037]], device='cuda:0')
When it is mlm output: 